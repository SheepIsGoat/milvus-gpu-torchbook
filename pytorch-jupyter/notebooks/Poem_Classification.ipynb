{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "593cbcde-ffa9-4e58-8da7-8f8741b7be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "raw_poe = requests.get('https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/edgar_allan_poe.txt').content\n",
    "raw_frost = requests.get('https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt').content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76a3929b-7aa7-49d1-953a-030b0699f7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/micromamba/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dask.array as da\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def decode_text(text):\n",
    "    return bytes(text.decode(\"utf-8\"), \"utf-8\").decode(\"unicode_escape\")\n",
    "\n",
    "def pad_array(jagged_array):\n",
    "    width = max((len(row) for row in jagged_array))\n",
    "    right_pad = lambda row: row + [\"\"]*(width-len(row))\n",
    "    return [right_pad(row) for row in jagged_array]\n",
    "\n",
    "def tokenize_line(line):\n",
    "    return np.array([\"$BEGINCHAR$\"] + [token.lemma_ for token in nlp(line)] + [\"$ENDCHAR$\"])\n",
    "\n",
    "def process_text(text, chunksize=500, pad=False):\n",
    "    enc_dec = decode_text(text)\n",
    "    jagged_array = [tokenize_line(line) for line in enc_dec.split(\"\\n\")]\n",
    "    array = pad_array(jagged_array) if pad else jagged_array\n",
    "    return np.array(array, dtype=str if pad else object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8cdb8d2-25fd-4394-b427-7bcc5e122148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def test_split_text(text):\n",
    "    array = process_text(text)\n",
    "    return train_test_split(array, random_state=1)\n",
    "    \n",
    "poe_train, poe_test = test_split_text(raw_poe)\n",
    "frost_train, frost_test = test_split_text(raw_frost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d46bb069-4e86-46ff-bda6-025c246ba099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "def flatten_array(array, jagged=True):\n",
    "    if jagged:\n",
    "        return np.array(list(chain.from_iterable(array)), dtype=str)\n",
    "    return array.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54666841-91a5-4b46-95ae-f475ff2deed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab counts - poe: 1047, frost: 1587, total: 2238\n"
     ]
    }
   ],
   "source": [
    "base = [\"$NEWCHAR$\"]\n",
    "vocab_p = np.unique(np.concatenate([base, flatten_array(poe_train)]))\n",
    "vocab_f = np.unique(np.concatenate([base, flatten_array(frost_train)]))\n",
    "total_vocab = np.unique(np.concatenate([vocab_p, vocab_f]))\n",
    "vocab_size = len(total_vocab)\n",
    "print(f\"Vocab counts - poe: {len(vocab_p)}, frost: {len(vocab_f)}, total: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5373656-2d2b-482e-81bc-18feca3aa803",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = total_vocab\n",
    "word2idx = {word:idx for idx, word in enumerate(idx2word)}\n",
    "del word2idx\n",
    "\n",
    "idx2word_p = vocab_p\n",
    "word2idx_p = {word:idx for idx, word in enumerate(idx2word_p)}\n",
    "\n",
    "idx2word_f = vocab_f\n",
    "word2idx_f = {word:idx for idx, word in enumerate(idx2word_f)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ddf81e16-8859-47ee-b955-f06abfec414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_arr(array, word2idx, ragged=True):\n",
    "    w2i_map = lambda word: word2idx.get(word, word2idx.get(\"$NEWCHAR$\"))\n",
    "    if not ragged:\n",
    "        return np.vectorize(w2i_map)(array)\n",
    "    return np.array([\n",
    "        np.array(\n",
    "            [w2i_map(word) for word in line], \n",
    "            dtype=int\n",
    "        ) for line in array\n",
    "    ], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d75d86d-4c36-48db-bbed-2e85695309f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "poe_vec_t = vectorize_arr(poe_train, word2idx_p)\n",
    "frost_vec_t = vectorize_arr(frost_train, word2idx_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af315f3c-1c62-41d7-9377-00cd7bb1b1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_corpora(corpora, vocab_size, ragged = True):\n",
    "    count = np.zeros(vocab_size, dtype=int)\n",
    "    if ragged:\n",
    "        def count_corpus(corpus):\n",
    "            for idx, row in enumerate(corpus):\n",
    "                np.add.at(count, row, 1)\n",
    "    \n",
    "        for corpus in corpora:\n",
    "            count_corpus(corpus)\n",
    "    else:\n",
    "        all_values = np.concatenate([corpus.ravel() for corpus in corpora])\n",
    "        np.add.at(count, all_values, 1)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a6e0b724-4eda-457f-9fb3-387eca2e2956",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora = [poe_vec_t, frost_vec_t]\n",
    "word_counter = count_corpora(corpora, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d74e230-5ca0-4429-9c4d-5befc48a275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transition_matrix(vec_arr, vocab_size, epsilon_smoothing=0.2, ragged=True):\n",
    "\n",
    "    # Account for unknown words\n",
    "    vocab_size += 1\n",
    "    \n",
    "    # Initialize matrices with zeros\n",
    "    trans_mat = np.zeros((vocab_size, vocab_size))\n",
    "    init_mat = np.zeros(vocab_size)\n",
    "\n",
    "    # For the initial states and transitions\n",
    "    if ragged:\n",
    "        for sentence in vec_arr:\n",
    "            if len(sentence) == 0:\n",
    "                continue\n",
    "            init_mat[sentence[0]] += 1\n",
    "            \n",
    "            for i in range(len(sentence)-1):\n",
    "                trans_mat[sentence[i], sentence[i+1]] += 1\n",
    "    else:\n",
    "        # For the initial states\n",
    "        starts = vec_arr[:, 0]\n",
    "        init_counts, _ = np.histogram(starts, bins=np.arange(vocab_size + 1))\n",
    "        init_mat += init_counts\n",
    "    \n",
    "        # For the transitions\n",
    "        y, x = vec_arr[:, :-1].ravel(), vec_arr[:, 1:].ravel()\n",
    "        hist, _, _ = np.histogram2d(x, y, bins=(vocab_size, vocab_size))\n",
    "        trans_mat += hist\n",
    "\n",
    "    \n",
    "    \n",
    "    # Apply epsilon smoothing\n",
    "    trans_mat += epsilon_smoothing\n",
    "    init_mat += epsilon_smoothing\n",
    "\n",
    "    # Normalize\n",
    "    normalized_trans_mat = trans_mat / trans_mat.sum(axis=1, keepdims=True)\n",
    "    normalized_init_mat = init_mat / init_mat.sum()\n",
    "    \n",
    "    return normalized_trans_mat, normalized_init_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed4025be-866a-4645-ac1f-24f4788aa896",
   "metadata": {},
   "outputs": [],
   "source": [
    "poe_t_mat, summy = get_transition_matrix(poe_vec_t, len(idx2word_p)) #vocab_size)\n",
    "frost_t_mat, _ = get_transition_matrix(frost_vec_t, len(idx2word_f)) #vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e60be3c9-987e-4de1-9c1e-7cef168732d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_probabilities(t_mat, max_err=10**-10):\n",
    "    return [i for i in np.sum(t_mat, axis=1) if abs(i-1)>max_err] == []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ebd61b30-6b4c-4d03-895f-0cef64dc7d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(verify_probabilities(poe_t_mat))\n",
    "print(verify_probabilities(frost_t_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fb767a8a-caac-458d-ad9c-c17289fe56e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def get_logprob_mat(t_mat):\n",
    "    vec_log = np.vectorize(math.log)\n",
    "    return vec_log(t_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b70daf26-0034-4b5f-9cd1-7f82af7f9321",
   "metadata": {},
   "outputs": [],
   "source": [
    "poe_logprob_t = get_logprob_mat(poe_t_mat)\n",
    "frost_logprob_t = get_logprob_mat(frost_t_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "176b2885-4d5e-433d-9b71-b29a59178efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_argprob(sequence, logprob_mat, word2idx):\n",
    "    encoded_sequence = vectorize_arr(sequence, word2idx, ragged=False)\n",
    "    argsum = 0\n",
    "    for i in range(len(encoded_sequence)-1):\n",
    "        argsum += logprob_mat[i, i+1]\n",
    "    return argsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "53eb41af-2f5c-47eb-83f4-1bf230e62b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_posterior(line, logprobs, word2idx):\n",
    "    # seq = np.array(tokenize_line(line))\n",
    "    best = -1*2**32\n",
    "    best_label = \"\"\n",
    "    for label, logprob_tmat in logprobs.items():\n",
    "        logprob = get_argprob(line, logprob_tmat, word2idx)\n",
    "        print(\"Label:\", label, \" logprob:\", logprob)\n",
    "        if logprob > best:\n",
    "            best = logprob\n",
    "            best_label = label\n",
    "    return best_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cffccf27-9380-4b67-92d9-ae58c674db1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poe\n"
     ]
    }
   ],
   "source": [
    "logprobs = {\n",
    "    \"Poe\": poe_logprob_t,\n",
    "    \"Frost\": frost_logprob_t\n",
    "}\n",
    "line = tokenize_line(\"These were days when my heart was volcanic As the scoriac rivers that roll\")\n",
    "result = estimate_posterior(line, logprobs, word2idx_p)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198cdec4-768d-4fab-8b71-997a8bd3eeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   is_poe  is_frost\n",
    "# |_______|_________| label_poe\n",
    "# |_______|_________| label_frost\n",
    "#\n",
    "results = {\n",
    "    \"Poe\": {}, \n",
    "    \"Frost\": {}\n",
    "}\n",
    "test_data = {\n",
    "    \"Poe\": poe_test,\n",
    "    \"Frost\": frost_test\n",
    "}\n",
    "labeled_w2i = {\n",
    "    \"Poe\": word2idx_p,\n",
    "    \"Frost\": word2idx_f\n",
    "}\n",
    "for label, data in test_data.items():\n",
    "    for line in data:\n",
    "        prediction = estimate_posterior(line, logprobs, labeled_w2i[label])\n",
    "        results[label][prediction] = results[label].get(prediction, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39193a7b-0e94-4204-9917-aa28d767150f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Poe': {'Poe': 200}, 'Frost': {'Poe': 396}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13ec0478-7e83-4258-9901-fbee6de6eef3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
